{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc599225-5bd3-4dda-8eeb-8f9d06ba9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy import units as u\n",
    "from astropy.coordinates import EarthLocation\n",
    "from astropy.time import Time\n",
    "from astropy.table import Table, join\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import ascii\n",
    "\n",
    "from astroplan import Observer, FixedTarget\n",
    "from astroplan import (AltitudeConstraint, AirmassConstraint, AtNightConstraint)\n",
    "from astroplan import is_observable, is_always_observable, months_observable\n",
    "from astroplan import observability_table\n",
    "from astroplan import time_grid_from_range\n",
    "from astroplan.plots import plot_sky, plot_airmass, plot_altitude\n",
    "import astroplan\n",
    "\n",
    "from collections import Counter\n",
    "from math import radians, cos, log10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import warnings \n",
    "\n",
    "main_catalogue_matched = Table.read('../data/catalogos/main_catalogue_matched_GAIA.csv', format='csv')\n",
    "\n",
    "main_catalogue_no_vr = main_catalogue_matched[main_catalogue_matched['radial_velocity'].mask == True]\n",
    "main_catalogue_no_vr.write('./tables/match_gaia_no_vr.csv', overwrite=True)\n",
    "print(\"Estrellas del match con GAIA sin VR:\", len(main_catalogue_no_vr))\n",
    "\n",
    "catalogue = Table.read('./tables/all_stars_without_vr.csv', format='csv')\n",
    "print(\"Total de estrellas sin VR en ninguno de los sondeos:\", len(catalogue))\n",
    "\n",
    "\n",
    "print(\"Los observatorios disponibles son: CASLEO, SPM, KPNO y SOAR\")\n",
    "location = input(\"Desde donde desea observar?\")\n",
    "\n",
    "if location == \"CASLEO\":\n",
    "    location = Observer(longitude=-69.2956*u.deg, latitude=-31.798*u.deg, elevation=2552*u.m, name=\"CASLEO\")\n",
    "    min_mag = 9\n",
    "    max_mag = 13\n",
    "elif location == \"SPM\":\n",
    "    location = Observer.at_site(\"spm\")\n",
    "    min_mag = 0\n",
    "    max_mag = 12\n",
    "elif location == \"KPNO\":\n",
    "    location = Observer.at_site(\"Kitt Peak\")\n",
    "    min_mag = 0\n",
    "    max_mag = 15\n",
    "elif location == \"SOAR\":\n",
    "    location = Observer.at_site(\"Cerro Pachon\")\n",
    "    min_mag = 14.9\n",
    "    max_mag = 17.7\n",
    "\n",
    "time_range = Time([\"2021-01-01 00:00\", \"2021-12-31 23:59\"]) # Inicializamos para observar 24/7 durante todo un año\n",
    "\n",
    "# ---------------------- --------------------- #\n",
    "#  DEFINIMOS LAS RESTRICCIONES OBSERVACIONALES #\n",
    "# -------------------------------------------- #\n",
    "\n",
    "# Calculamos la masa de aire\n",
    "az_degrees = 45\n",
    "az_radians = radians(az_degrees)\n",
    "airmass = 1/(cos(az_radians))\n",
    "\n",
    "print(\"Masa de aire:\", airmass)\n",
    "\n",
    "constraints = [AirmassConstraint(airmass), AtNightConstraint.twilight_civil()]\n",
    "\n",
    "# --------------------- #\n",
    "#  FILTRADOS Y TARGETS  #\n",
    "# --------------------- #  \n",
    "\n",
    "targets_no_vr = [FixedTarget(coord=SkyCoord(ra=RA*u.deg, dec=DEC*u.deg), name=ID, ra=RA, dec=DEC)\n",
    "               for ID,RA,DEC,YNMG,phot_g_mean_mag,phot_bp_mean_mag,phot_rp_mean_mag,radial_velocity,teff_val,APOGEE_ID,VHELIO_AVG,\n",
    "                   galah_sobject_id,rv_galah,lamost_mobsid,rv_b0,rv_r0\n",
    "                in catalogue]\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6843e2f-bcd5-4091-85c7-053fe293bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_table = astroplan.observability_table(constraints, location, targets_no_vr, time_range=time_range)\n",
    "obs_table.rename_column('target name', 'ID')\n",
    "obs_table.rename_column('ever observable', 'ever_obs')\n",
    "obs_table.rename_column('always observable', 'always_obs')\n",
    "obs_table.rename_column('fraction of time observable', 'fraction_obs')\n",
    "catalogue_obs = join(catalogue, obs_table)\n",
    "\n",
    "catalogue_ever_obs = catalogue_obs[(catalogue_obs['ever_obs'] == True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742eb153-6556-4a4b-9099-badc44fa712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_catalogue = catalogue_ever_obs[(catalogue_ever_obs['phot_g_mean_mag'] < max_mag) & (catalogue_ever_obs['phot_g_mean_mag'] > min_mag)]\n",
    "print(\"Estrellas que pueden ser observadas en algún momento:\", len(main_catalogue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16046ab3-77ef-4d15-bbf2-dcf91b0448dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------- #\n",
    "#    ANÁLISIS DE TODAS LAS ESTRELLAS OBSERVABLES     #\n",
    "# -------------------------------------------------- #\n",
    "\n",
    "def group_num_dict(catalogue):\n",
    "    groups = {}\n",
    "    for star in catalogue:\n",
    "        key = star['YNMG']\n",
    "        if key not in groups:\n",
    "            groups[key] = 0\n",
    "        groups[key] += 1\n",
    "    \n",
    "    return groups\n",
    "\n",
    "total_groups = group_num_dict(catalogue)\n",
    "\n",
    "# Agrupaciones por cantidad en forma de diccionario\n",
    "total_obs_num_groups = group_num_dict(main_catalogue)\n",
    "total_obs_num_groups_sorted = sorted(total_obs_num_groups.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Agrupaciones por nombre en forma de diccionario\n",
    "\n",
    "def group_name_dict(catalogue):\n",
    "    total_obs_name_groups = {}\n",
    "    for star in catalogue:\n",
    "        key = star['YNMG']\n",
    "        value = star['ID']\n",
    "        if key not in total_obs_name_groups:\n",
    "            total_obs_name_groups[key] = []\n",
    "        total_obs_name_groups[key].append(value)\n",
    "    \n",
    "    return total_obs_name_groups\n",
    "\n",
    "total_obs_name_groups = group_name_dict(main_catalogue)\n",
    "\n",
    "# ---------------------------- #\n",
    "#    CREACIÓN DE TABLA FINAL   #\n",
    "# ---------------------------- #\n",
    "\n",
    "nymg = [] # array con los nymg\n",
    "total_amount = [] # array con el total de los nymg\n",
    "           \n",
    "def build_amount(array, dic): # devuelve un array con dic.values de dic.keys que pertenecen al array\n",
    "    amount = []           \n",
    "    for group in array:\n",
    "        if group in dic.keys():\n",
    "            amount.append(dic[group])\n",
    "        else:\n",
    "            amount.append(0)\n",
    "    return amount\n",
    "\n",
    "# Categorizamos por grupos inciertos\n",
    "\n",
    "uncertain_amount = 0 # cantidad total de estrellas con agrupaciones inciertas\n",
    "uncertain_groups = {} # agrupaciones inciertas y sus cantidades\n",
    "for key, value in total_groups.items():\n",
    "    if ';' in key or '_' in key or '-' in key or 'Ambiguous' in key:\n",
    "        uncertain_amount += total_groups[key]\n",
    "        uncertain_groups[key] = total_groups[key]\n",
    "        next\n",
    "    else:\n",
    "        nymg.append(key)\n",
    "        total_amount.append(value)\n",
    "\n",
    "total_no_vr_groups = group_num_dict(catalogue) # dicccionario con los nymg sin vr y sus cantidades \n",
    "\n",
    "total_no_vr_amount = build_amount(nymg, total_no_vr_groups) # array con el total de candidatos sin vr    \n",
    "\n",
    "def uncertain(dic1, dic2): # cantidad de elementos en dic1 que hay en dic2\n",
    "    amount = 0\n",
    "    for uncertain in dic1.keys():\n",
    "        if uncertain in dic2.keys():\n",
    "            amount += dic2[uncertain]\n",
    "    return amount\n",
    "\n",
    "uncertain_no_vr_amount = uncertain(uncertain_groups,total_no_vr_groups) # vemos cuantos no tienen vr\n",
    "\n",
    "# Agregamos la info asociada a los uncertains a cada columna\n",
    "total_amount.append(uncertain_amount)\n",
    "total_no_vr_amount.append(uncertain_no_vr_amount)\n",
    "\n",
    "if location.name == 'spm':\n",
    "    observable_spm = build_amount(nymg, total_obs_num_groups)     \n",
    "    observable_spm.append(uncertain(uncertain_groups, total_obs_num_groups))\n",
    "if location.name == 'CASLEO':\n",
    "    observable_casleo = build_amount(nymg, total_obs_num_groups)\n",
    "    observable_casleo.append(uncertain(uncertain_groups, total_obs_num_groups))       \n",
    "if location.name == 'Kitt Peak':\n",
    "    observable_kpno = build_amount(nymg, total_obs_num_groups)\n",
    "    observable_kpno.append(uncertain(uncertain_groups, total_obs_num_groups))       \n",
    "if location.name == 'Cerro Pachon':\n",
    "    observable_soar = build_amount(nymg, total_obs_num_groups)   \n",
    "    observable_soar.append(uncertain(uncertain_groups, total_obs_num_groups))\n",
    "\n",
    "nymg.append('Uncertain')\n",
    "    \n",
    "if observable_spm != [] and observable_casleo != [] and observable_kpno != [] and observable_soar != []:\n",
    "    resume_table = Table([nymg, total_amount, total_no_vr_amount, observable_spm, observable_casleo, observable_kpno, observable_soar],\n",
    "                      names=('YNMG', 'total_amount', 'total_no_vr_amount', 'observable_spm', 'observable_casleo', 'observable_kpno', 'observable_soar'))\n",
    "    #resume_table.add_row(['Uncertain', uncertain_amount, uncertain_li_amount, uncertain_spm, uncertain_casleo, uncertain_kpno, uncertain_soar])\n",
    "    resume_table.add_row(['TOTAL', np.sum(total_amount), np.sum(total_no_vr_amount), np.sum(observable_spm), np.sum(observable_casleo),\n",
    "                          np.sum(observable_kpno), np.sum(observable_soar)])\n",
    "    ascii.write(resume_table, format='latex')  \n",
    "    resume_table.write('./tables/resume_table_no_vr.csv', overwrite=True)\n",
    "    resume_table.write('./tables/resume_table_no_vr.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740feae-a38a-44f5-86cf-1e9276e381c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------- #\n",
    "#   CALCULAMOS EL TIEMPO DE INTEGRACIÓN   #\n",
    "# --------------------------------------- #\n",
    "\n",
    "exposure_times = Table.read('../data/exposure_times/exposure_times_obs.csv', format='csv')   \n",
    "\n",
    "# Filtramos por información del observatorio elegido\n",
    "if location.name == 'CASLEO':\n",
    "    exposure_times_location = exposure_times[exposure_times['observatory'] == 'casleo']\n",
    "elif location.name == 'Cerro Pachon':\n",
    "    exposure_times_location = exposure_times[exposure_times['observatory'] == 'soar']\n",
    "elif location.name == 'Kitt Peak':\n",
    "    exposure_times_location = exposure_times[exposure_times['observatory'] == 'kpno']\n",
    "else:\n",
    "    exposure_times_location = exposure_times[exposure_times['observatory'] == location.name]\n",
    "\n",
    "exposure_times_sec = np.round(np.interp(main_catalogue['phot_g_mean_mag'], exposure_times_location['mag_V'], exposure_times_location['exposure_time_sec']), 0)\n",
    "exposure_times_sec = exposure_times_sec.astype(int)\n",
    "total_exposure_time_sec = int(np.sum(exposure_times_sec))\n",
    "            \n",
    "total_exposure_time_hrs = np.round(total_exposure_time_sec / 3600, 1);\n",
    "            \n",
    "print(f\"El tiempo total de integración necesario para observar las {len(main_catalogue)} estrellas es:\", total_exposure_time_sec, \"segundos.\")\n",
    "print(\"Su equivalente en horas es:\", total_exposure_time_hrs)\n",
    "\n",
    "#total_main_catalogue.remove_column('exposure_time_sec')\n",
    "if 'exposure_time_sec' not in main_catalogue.columns:\n",
    "    main_catalogue['exposure_time_sec'] = exposure_times_sec\n",
    "\n",
    "# Tiempos de integración por agrupación observable\n",
    "total_obs_exposure_times_groups = {}\n",
    "for key in total_obs_num_groups.keys():\n",
    "    exposure_time_sec_per_key = 0\n",
    "    for target in main_catalogue:\n",
    "        if key == target['YNMG']:             \n",
    "            exposure_time_sec_per_key += target['exposure_time_sec']\n",
    "    total_obs_exposure_times_groups[key] = exposure_time_sec_per_key\n",
    "\n",
    "print(\"Tiempos de integración para observar la totalidad de las poblaciones observables\")\n",
    "uncertain_exposure_times = 0\n",
    "for key, value in total_obs_exposure_times_groups.items():        \n",
    "    if key in uncertain_groups.keys():\n",
    "        uncertain_exposure_times += value\n",
    "    else:\n",
    "        print(key, \":\", value, \"seg /\", np.round(value / 3600, 1), \"hrs\")\n",
    "        \n",
    "if uncertain_exposure_times != 0:        \n",
    "    print(\"Uncertain:\", uncertain_exposure_times, \"seg /\", np.round(uncertain_exposure_times / 3600, 1), \"hrs\")\n",
    "    \n",
    "# ------------------------------------------------------ #\n",
    "#   CONSTURIMOS UNA TABLA CON LOS TIEMPOS DE EXPOSICION  #\n",
    "# ------------------------------------------------------ #\n",
    "\n",
    "groups_obs = [] #array con las agrupaciones observables\n",
    "groups_number_obs = [] #array con la cantidad de estrellas en agrupaciones observables\n",
    "for key,value in total_obs_num_groups.items():\n",
    "    if key not in uncertain_groups.keys():\n",
    "        groups_obs.append(key)\n",
    "        groups_number_obs.append(value)  \n",
    "\n",
    "exposure_time_per_group_sec = []\n",
    "for key, value in total_obs_exposure_times_groups.items():\n",
    "    if key not in uncertain_groups.keys():\n",
    "        exposure_time_per_group_sec.append(value)\n",
    "    \n",
    "uncertain_groups_num = uncertain(uncertain_groups, total_obs_num_groups);\n",
    "if uncertain_groups_num != 0:\n",
    "    groups_obs.append('Uncertain')\n",
    "    groups_number_obs.append(uncertain_groups_num)\n",
    "    exposure_time_per_group_sec.append(uncertain_exposure_times)\n",
    "    \n",
    "exposure_time_per_group_hrs = [np.round(i / 3600, 1) for i in exposure_time_per_group_sec]\n",
    "\n",
    "if location.name == 'spm':\n",
    "    overhead_spm = 600 #10 min\n",
    "    total_overhead = [np.round((i * overhead_spm) / 3600, 1) for i in groups_number_obs]\n",
    "    total_obs_time_per_group_hrs = np.round(np.add(exposure_time_per_group_hrs, total_overhead), 1)    \n",
    "    exposure_times_table_spm = Table([groups_obs, groups_number_obs, exposure_time_per_group_hrs, total_obs_time_per_group_hrs],\n",
    "                                      names=('YNMG', 'total_amount', 'exposure_time_hrs', 'total_time_hrs'))\n",
    "    exposure_times_table_spm.add_row(['TOTAL', np.sum(groups_number_obs), total_exposure_time_hrs, np.round(np.sum(total_obs_time_per_group_hrs), 2)])\n",
    "    ascii.write(exposure_times_table_spm, format='latex')  \n",
    "    exposure_times_table_spm.write('./tables/exposure_times_table_spm_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'CASLEO':\n",
    "    exposure_times_table_casleo = Table([groups_obs, groups_number_obs, exposure_time_per_group_hrs],\n",
    "                                      names=('YNMG', 'total_amount', 'exposure_time_hrs'))\n",
    "    exposure_times_table_casleo.add_row(['TOTAL', np.sum(groups_number_obs), total_exposure_time_hrs])\n",
    "    ascii.write(exposure_times_table_casleo, format='latex')  \n",
    "    exposure_times_table_casleo.write('./tables/exposure_times_table_casleo_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'Kitt Peak':\n",
    "    overhead_kpno = 300 #5 min\n",
    "    total_overhead = [np.round((i * overhead_kpno) / 3600, 1) for i in groups_number_obs]\n",
    "    total_obs_time_per_group_hrs = np.round(np.add(exposure_time_per_group_hrs, total_overhead), 1)    \n",
    "    exposure_times_table_kpno = Table([groups_obs, groups_number_obs, exposure_time_per_group_hrs, total_obs_time_per_group_hrs],\n",
    "                                      names=('YNMG', 'total_amount', 'exposure_time_hrs', 'total_time_hrs'))\n",
    "    exposure_times_table_kpno.add_row(['TOTAL', np.sum(groups_number_obs), total_exposure_time_hrs, np.round(np.sum(total_obs_time_per_group_hrs), 2)])\n",
    "    ascii.write(exposure_times_table_kpno, format='latex')  \n",
    "    exposure_times_table_kpno.write('./tables/exposure_times_table_kpno_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'Cerro Pachon':\n",
    "    overhead_soar = 144 #2.4 min\n",
    "    total_overhead = [np.round((i * overhead_soar) / 3600, 1) for i in groups_number_obs]\n",
    "    total_obs_time_per_group_hrs = np.round(np.add(exposure_time_per_group_hrs, total_overhead), 1)\n",
    "    exposure_times_table_soar = Table([groups_obs, groups_number_obs, exposure_time_per_group_hrs, total_obs_time_per_group_hrs],\n",
    "                                      names=('YNMG', 'total_amount', 'exposure_time_hrs', 'total_time_hrs'))\n",
    "    exposure_times_table_soar.add_row(['TOTAL', np.sum(groups_number_obs), total_exposure_time_hrs, np.round(np.sum(total_obs_time_per_group_hrs), 2)])\n",
    "    ascii.write(exposure_times_table_soar, format='latex')  \n",
    "    exposure_times_table_soar.write('./tables/exposure_times_table_soar_no_vr.csv', overwrite=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441064d3-80c5-43d4-9d8a-32027655d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------- #\n",
    "#   CONSTURIMOS UNA TABLA CON LOS CANDIDATOS DE BPMG Y UNCERTAIN   #\n",
    "# ---------------------------------------------------------------- #\n",
    "\n",
    "def bpmg_from_obs():\n",
    "    bpmg_table = main_catalogue[main_catalogue['YNMG'] == 'BPMG']\n",
    "    bpmg_table.keep_columns(['ID', 'RA', 'DEC', 'phot_g_mean_mag', 'radial_velocity', 'teff_val', 'radius_val', 'lum_val', 'distances', 'fraction_obs', 'exposure_time_sec'])\n",
    "    bpmg_table['RA'] = np.round(bpmg_table['RA'], 4)\n",
    "    bpmg_table['DEC'] = np.round(bpmg_table['DEC'], 3)\n",
    "    bpmg_table['phot_g_mean_mag'] = np.round(bpmg_table['phot_g_mean_mag'], 2)\n",
    "    bpmg_table['teff_val'] = np.round(bpmg_table['teff_val'], 0)\n",
    "    bpmg_table['distances'] = np.round(bpmg_table['distances'], 2)\n",
    "    bpmg_table['fraction_obs'] = np.round(bpmg_table['fraction_obs'] * 100, 1)\n",
    "    \n",
    "    return bpmg_table\n",
    "\n",
    "def uncertain_from_obs():\n",
    "    uncertain_id = []\n",
    "    uncertain_nymg = []\n",
    "    uncertain_ra = []\n",
    "    uncertain_dec = []\n",
    "    uncertain_mag = []\n",
    "    uncertain_rv = []\n",
    "    uncertain_teff = []\n",
    "    uncertain_rad = []\n",
    "    uncertain_lum = []\n",
    "    uncertain_dist = []\n",
    "    uncertain_obs = []\n",
    "    uncertain_exp = []\n",
    "\n",
    "    for target in main_catalogue:\n",
    "        if target['YNMG'] in uncertain_groups.keys():\n",
    "            uncertain_id.append(target['ID'])\n",
    "            uncertain_nymg.append(target['YNMG'])\n",
    "            uncertain_ra.append(target['RA'])\n",
    "            uncertain_dec.append(target['DEC'])\n",
    "            uncertain_mag.append(target['phot_g_mean_mag'])\n",
    "            uncertain_rv.append(target['radial_velocity'])\n",
    "            uncertain_teff.append(target['teff_val'])\n",
    "            uncertain_rad.append(target['radius_val'])\n",
    "            uncertain_lum.append(target['lum_val'])\n",
    "            uncertain_dist.append(target['distances'])\n",
    "            uncertain_obs.append(target['fraction_obs'])\n",
    "            uncertain_exp.append(target['exposure_time_sec'])\n",
    "     \n",
    "    uncertain_table = Table([uncertain_id, uncertain_nymg, uncertain_ra, uncertain_dec, uncertain_mag, uncertain_rv, uncertain_teff, uncertain_rad, \n",
    "                                   uncertain_lum, uncertain_dist, uncertain_obs, uncertain_exp], \n",
    "                                    names = ('ID', 'YNMG', 'RA', 'DEC', 'phot_mean_g_mag', 'radial_velocity', 'teff_val', 'radius_val', 'lum_val', 'distances', \n",
    "                                               'fraction_obs', 'exposure_time_sec'))\n",
    "    uncertain_table['distances'] = np.round(uncertain_table['distances'], 2)\n",
    "    uncertain_table['fraction_obs'] = np.round(uncertain_table['fraction_obs'], 2)\n",
    "    \n",
    "    return uncertain_table\n",
    "\n",
    "if location.name == 'spm':\n",
    "    bpmg_from_spm = bpmg_from_obs()\n",
    "    ascii.write(bpmg_from_spm, format='latex')  \n",
    "    bpmg_from_spm.write('./tables/bpmg_from_spm_no_vr.csv', overwrite=True)\n",
    "    \n",
    "    uncertain_from_spm = uncertain_from_obs()\n",
    "    ascii.write(uncertain_from_spm, format='latex')  \n",
    "    uncertain_from_spm.write('./tables/uncertain_from_spm_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'CASLEO':\n",
    "    bpmg_from_casleo = bpmg_from_obs()\n",
    "    ascii.write(bpmg_from_casleo, format='latex')  \n",
    "    bpmg_from_casleo.write('./tables/bpmg_from_casleo_no_vr.csv', overwrite=True)\n",
    "    \n",
    "    uncertain_from_casleo = uncertain_from_obs()\n",
    "    ascii.write(uncertain_from_casleo, format='latex')  \n",
    "    uncertain_from_casleo.write('./tables/uncertain_from_casleo_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'Kitt Peak':    \n",
    "    bpmg_from_kpno = bpmg_from_obs()\n",
    "    ascii.write(bpmg_from_kpno, format='latex')  \n",
    "    bpmg_from_kpno.write('./tables/bpmg_from_kpno_no_vr.csv', overwrite=True)\n",
    "    \n",
    "    uncertain_from_kpno = uncertain_from_obs()\n",
    "    ascii.write(uncertain_from_kpno, format='latex')  \n",
    "    uncertain_from_kpno.write('./tables/uncertain_from_kpno_no_vr.csv', overwrite=True)\n",
    "    \n",
    "if location.name == 'Cerro Pachon':\n",
    "    bpmg_from_soar = bpmg_from_obs()\n",
    "    ascii.write(bpmg_from_soar, format='latex')  \n",
    "    bpmg_from_soar.write('./tables/bpmg_from_soar_no_vr.csv', overwrite=True)\n",
    "    \n",
    "    uncertain_from_soar = uncertain_from_obs()\n",
    "    ascii.write(uncertain_from_soar, format='latex')  \n",
    "    uncertain_from_soar.write('./tables/uncertain_from_soar_no_vr.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1685e2-3461-4a56-97dd-04d4ca07530f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
